{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cartopy pandas matplotlib chardet xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeatures\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Local\n",
    "from jaguar_feature_scaling import get_added_features_plot,get_temporal_analysis_plot\n",
    "from helper import get_dataset_with_copy, calculate_group_directions, calculate_group_distances, remove_outliers, create_time_window_features,calculate_movement_features, classify_movement_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas configuration\n",
    "Configure pandas display settings to show more data in our notebook outputs\n",
    "This helps us see more rows and columns when examining our dataframes, rather than having them truncated with ellipsis (...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be set to see most of the infomation of any print that i make\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading and copy variable declaration\n",
    "We create two versions of our dataframe: main and copy\n",
    "The copy preserves our original, untouched data as a backup reference, while the main dataframe will be used for active analysis and transformations.\n",
    "This is particularly useful in Jupyter notebooks where we can always refer back to the original state of our data without reloading the file or having to restart the notebook to run it all again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the file encoding\n",
    "jaguar_data_original, jaguar_data = get_dataset_with_copy('datasets/jaguar_movement_data.csv')\n",
    "\n",
    "jaguar_info_original, jaguar_info = get_dataset_with_copy('datasets/jaguar_additional_information_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Exploration\n",
    "Display basic information about both datasets including their structure and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_data_original.head())\n",
    "print(jaguar_data_original.shape)\n",
    "print(jaguar_info_original.head())\n",
    "print(jaguar_info_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check detailed information about data types and null values in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_data_original.info())\n",
    "print(jaguar_info_original.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Analysis\n",
    "Analyze and visualize gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_info_original['Sex'].unique())\n",
    "gender = jaguar_info_original['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bar plot for gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender.plot(kind='bar',figsize=(10,10))\n",
    "plt.title('Number of birds detected')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Check\n",
    "Check for missing values in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_data_original.isnull().sum())\n",
    "print(\"---------\")\n",
    "print(jaguar_info_original.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check unique values in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_data_original.nunique())\n",
    "print(\"---------\")\n",
    "print(jaguar_info_original.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Treatment\n",
    "Since there are null values in the columns \"Estimated Age\" and \"Weight\" (jaguar_info) we will be filling them 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_info[\"Estimated Age\"]= jaguar_info[\"Estimated Age\"].fillna(value=0)\n",
    "jaguar_info[\"Weight\"]= jaguar_info[\"Weight\"].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all columns in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jaguar_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjaguar_data\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(jaguar_info\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jaguar_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(jaguar_data.columns.to_list())\n",
    "print(jaguar_info.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns and drop unnecessary ones.\n",
    "We remove unnecesary or unique value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_data.rename(columns={'location.long': 'longitude', 'location.lat': 'latitude', 'individual.local.identifier (ID)': 'individual_id' }, inplace=True)\n",
    "jaguar_data.drop(['Event_ID', 'individual.taxon.canonical.name','tag.local.identifier', 'study.name', 'country'], axis=1,inplace=True)\n",
    "jaguar_info.rename(columns={'ID':'individual_id','Sex': 'sex', 'Estimated Age': 'age', 'Weight': 'weight' }, inplace=True)\n",
    "jaguar_info.drop(['Collar Type', 'Collar Brand','Planned Schedule', 'Project Leader', 'Contact'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_data['timestamp'] = pd.to_datetime(jaguar_data['timestamp'], errors='coerce')\n",
    "print(jaguar_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all the columns in both datasets to confirm the changes we've done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_data.columns.to_list())\n",
    "print(jaguar_info.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Merge and Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets.\n",
    "We merge them using the id of the individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew = jaguar_data.merge(jaguar_info, on='individual_id', how='left')\n",
    "print(jaguar_datanew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping. We create a dictionary where each key is the id of the jaguar and the value is their tracking and information data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_groups = {individual_id: group for individual_id, group in jaguar_datanew.groupby('individual_id')}\n",
    "print(jaguar_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print record count for each jaguar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jaguar_id, subset in jaguar_groups.items():\n",
    "    print(f\"Jaguar {jaguar_id}: {len(subset)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Features\n",
    "Adding time-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew['hour'] = jaguar_datanew['timestamp'].dt.hour\n",
    "jaguar_datanew['day'] = jaguar_datanew['timestamp'].dt.day\n",
    "jaguar_datanew['month'] = jaguar_datanew['timestamp'].dt.month\n",
    "jaguar_datanew['year'] = jaguar_datanew['timestamp'].dt.year\n",
    "jaguar_datanew['dayofweek'] = jaguar_datanew['timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create time period categories:\n",
    "- 0 (24) to 6 : Night\n",
    "- 6 to 12: Morning\n",
    "- 12 to 18: Afternoon\n",
    "- 18 to 24 (0): Evening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew['time_of_day'] = pd.cut(jaguar_datanew['hour'], bins=[0, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movement Analysis Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be calculating:\n",
    "- Time differences between consecutive points for each jaguar\n",
    "- Distances\n",
    "- Speed\n",
    "- Direction of movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew['time_diff'] = jaguar_datanew.groupby('individual_id')['timestamp'].diff()\n",
    "jaguar_datanew['distance'] = jaguar_datanew.groupby('individual_id', group_keys=False).apply(calculate_group_distances)\n",
    "jaguar_datanew['time_diff_hours'] = jaguar_datanew['time_diff'].dt.total_seconds() / 3600\n",
    "jaguar_datanew['speed'] = jaguar_datanew['distance'] / jaguar_datanew['time_diff_hours'].replace({0: np.nan})\n",
    "jaguar_datanew['direction'] = jaguar_datanew.groupby('individual_id', group_keys=False).apply(calculate_group_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Validation\n",
    "Handle infinite values and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew = jaguar_datanew.replace([np.inf, -np.inf], np.nan)\n",
    "jaguar_datanew = remove_outliers(jaguar_datanew, 'speed')\n",
    "jaguar_datanew = remove_outliers(jaguar_datanew, 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_datanew['speed'] = jaguar_datanew['speed'].fillna(method='ffill')\n",
    "jaguar_datanew['distance'] = jaguar_datanew['distance'].fillna(method='ffill')\n",
    "jaguar_datanew['direction'] = jaguar_datanew['direction'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Validation\n",
    "Display processed data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_datanew[['individual_id', 'timestamp', 'latitude', 'longitude', 'distance', 'speed', 'direction']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaguar_datanew['distance'].describe())\n",
    "print(\"-----\")\n",
    "print(jaguar_datanew['speed'].describe())\n",
    "print(\"-----\")\n",
    "print(jaguar_datanew['direction'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_plt = get_added_features_plot(jaguar_datanew)\n",
    "features_plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional temporal analysis\n",
    "travaled_distance_plt = get_temporal_analysis_plot(jaguar_datanew)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual jaguar movement patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "# Set the extent to the whole world (-180 to 180 longitude, -90 to 90 latitude)\n",
    "# ax.set_global()\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeatures.LAND, edgecolor='black')\n",
    "ax.add_feature(cfeatures.OCEAN)\n",
    "ax.add_feature(cfeatures.COASTLINE)\n",
    "ax.add_feature(cfeatures.BORDERS, linestyle=':')\n",
    "\n",
    "# Plot each jaguar's movement\n",
    "\n",
    "for jaguar_id in jaguar_datanew['individual_id'].unique():\n",
    "    jaguar_subset = jaguar_datanew[jaguar_datanew['individual_id'] == jaguar_id]\n",
    "    ax.plot(jaguar_subset['longitude'], jaguar_subset['latitude'], \n",
    "             label=f'Jaguar {jaguar_id}', alpha=1)\n",
    "\n",
    "# Labels and legend\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.set_title(\"Jaguar Movement Paths on World Map\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMovement Statistics by Time of Day:\")\n",
    "print(jaguar_datanew.groupby('time_of_day')[['speed', 'distance']].agg(['mean', 'std']).round(3))\n",
    "\n",
    "print(\"\\nMovement Statistics by Individual:\")\n",
    "print(jaguar_datanew.groupby('individual_id')[['speed', 'distance']].agg(['mean', 'std']).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "As we can see in the plotted correlation matrix underneath:\n",
    "There is a strong correlation between the following columns:\n",
    "    - Latitude and longitude (Negative)\n",
    "There is also moderate correlation between:\n",
    "    - Timestamp and latitude (positive)\n",
    "There is a weak or no correlation at all between (values closer to 0 both negative and positive):\n",
    "    - Individual id and latitude\n",
    "    - Individual id and longitude\n",
    "    - Timestamp and longitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = jaguar_datanew.select_dtypes(include=[np.number]).columns\n",
    "correlation_data = jaguar_datanew[numeric_columns].corr()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(correlation_data,  annot=True)\n",
    "\n",
    "#Filtering Out Self-Correlations\n",
    "# Unstack the correlation matrix\n",
    "correlation_pairs = correlation_data.unstack()\n",
    "\n",
    "# Filter out self-correlations (where feature pairs are the same)\n",
    "filtered_correlation_pairs = correlation_pairs[correlation_pairs.index.get_level_values(0) != correlation_pairs.index.get_level_values(1)]\n",
    "\n",
    "# Sort the remaining pairs in descending order of correlation\n",
    "filtered_correlation_pairs = filtered_correlation_pairs.sort_values(kind=\"quicksort\", ascending=True)\n",
    "\n",
    "print(filtered_correlation_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for jaguar_id, subset in jaguar_groups.items():\n",
    "#     ax1 = subset.head().plot.scatter(x='timestamp',\n",
    "#                        y='longitude',\n",
    "#                        c='DarkBlue')\n",
    "    #print(subset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset (unsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguar_data_copy = jaguar_data.copy()\n",
    "X_copy = jaguar_data_copy.drop('individual_id', axis=1)\n",
    "X_copy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_copy = jaguar_data_copy['individual_id']         # we want to predict y using X\n",
    "y_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Split the dataset: tes=25%; training=75%\n",
    "# test size=25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_copy,y_copy,test_size=0.25,random_state=40)\n",
    "\n",
    "print(len(X_train)*100/len(jaguar_data_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = []\n",
    "for jaguar_id in jaguar_datanew['individual_id'].unique():\n",
    "    # Get data for current jaguar\n",
    "    jaguar_data = jaguar_datanew[jaguar_datanew['individual_id'] == jaguar_id].copy()\n",
    "    \n",
    "    # Calculate window features without setting index beforehand\n",
    "    window_stats = create_time_window_features(jaguar_data)\n",
    "    window_stats['individual_id'] = jaguar_id\n",
    "    window_features.append(window_stats)\n",
    "    \n",
    "window_features_df = pd.concat(window_features).reset_index()\n",
    "\n",
    "window_features_df = calculate_movement_features(window_features_df)\n",
    "\n",
    "# 3. Add temporal context features\n",
    "window_features_df['hour'] = window_features_df['timestamp'].dt.hour\n",
    "window_features_df['is_night'] = (window_features_df['hour'] >= 18) | (window_features_df['hour'] <= 6)\n",
    "window_features_df['is_peak_activity'] = window_features_df['hour'].isin([5,6,7,17,18,19])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features_df['movement_state'] = window_features_df.apply(classify_movement_state, axis=1)\n",
    "\n",
    "# Let's visualize our new features\n",
    "plt.figure(figsize=(15, 30))\n",
    "\n",
    "# Plot 1: Movement States Distribution\n",
    "plt.subplot(4, 1, 1)\n",
    "sns.countplot(data=window_features_df, x='movement_state')\n",
    "plt.title('Distribution of Movement States')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 2: Speed vs Area Covered\n",
    "plt.subplot(4, 1, 2)\n",
    "sns.scatterplot(data=window_features_df, x='speed_mean', y='area_covered', \n",
    "                hue='movement_state', alpha=0.6)\n",
    "plt.title('Speed vs Area Covered by Movement State')\n",
    "\n",
    "# Plot 3: Movement Patterns by Time of Day\n",
    "plt.subplot(4, 1, 3)\n",
    "sns.boxplot(data=window_features_df, x='hour', y='movement_intensity')\n",
    "plt.title('Movement Intensity by Hour')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 4: Path Efficiency Distribution\n",
    "plt.subplot(4, 1, 4)\n",
    "sns.boxplot(data=window_features_df, x='movement_state', y='path_efficiency')\n",
    "plt.title('Path Efficiency by Movement State')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics of our engineered features\n",
    "print(\"\\nSummary Statistics of Engineered Features:\")\n",
    "print(window_features_df.describe().round(3))\n",
    "\n",
    "print(\"\\nMovement State Distribution:\")\n",
    "print(window_features_df['movement_state'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's prepare our features and target\n",
    "# Drop non-feature columns and handle any remaining NaN values\n",
    "feature_columns = ['speed_mean', 'speed_max', 'speed_std', 'distance_sum', 'distance_mean', 'direction_mean', 'direction_std', 'area_covered', 'movement_intensity', 'path_efficiency', 'direction_variability', 'hour', 'is_night', 'is_peak_activity']\n",
    "\n",
    "X = window_features_df[feature_columns].fillna(0)\n",
    "y = window_features_df['movement_state']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of pipelines with different models\n",
    "# pipelines = {\n",
    "#     'random_forest': Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "#     ]),\n",
    "    \n",
    "#     'svm': Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('classifier', SVC(kernel='rbf', probability=True))\n",
    "#     ]),\n",
    "    \n",
    "#     'logistic': Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('classifier', LogisticRegression(max_iter=1000))\n",
    "#     ]),\n",
    "    \n",
    "#     'xgboost': Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('classifier', xgb.XGBClassifier(random_state=42))\n",
    "#     ])\n",
    "# }\n",
    "\n",
    "pipelines = {\n",
    "    'random_forest': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=50, random_state=42))  # reduced from 100\n",
    "    ]),\n",
    "    'logistic': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(max_iter=500))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'pipeline': pipeline,\n",
    "        'train_score': pipeline.score(X_train, y_train),\n",
    "        'test_score': pipeline.score(X_test, y_test),\n",
    "        'cv_scores': cross_val_score(pipeline, X_train, y_train, cv=5),\n",
    "        'predictions': y_pred,\n",
    "        'classification_report': classification_report(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name.upper()} RESULTS:\")\n",
    "    print(f\"Training Score: {result['train_score']:.4f}\")\n",
    "    print(f\"Test Score: {result['test_score']:.4f}\")\n",
    "    print(f\"Cross-validation Scores: {result['cv_scores'].mean():.4f} (+/- {result['cv_scores'].std() * 2:.4f})\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(result['classification_report'])\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Model Comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "model_scores = {name: result['test_score'] for name, result in results.items()}\n",
    "plt.bar(model_scores.keys(), model_scores.values())\n",
    "plt.title('Model Test Scores Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Plot 2: Cross-validation Scores\n",
    "plt.subplot(2, 2, 2)\n",
    "cv_means = [result['cv_scores'].mean() for result in results.values()]\n",
    "cv_stds = [result['cv_scores'].std() for result in results.values()]\n",
    "plt.errorbar(results.keys(), cv_means, yerr=cv_stds, fmt='o')\n",
    "plt.title('Cross-validation Scores with Standard Deviation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('CV Score')\n",
    "\n",
    "# Plot 3: Feature Importance (for Random Forest)\n",
    "rf_pipeline = results['random_forest']['pipeline']\n",
    "rf_classifier = rf_pipeline.named_steps['classifier']\n",
    "importances = pd.Series(\n",
    "    rf_classifier.feature_importances_,\n",
    "    index=feature_columns\n",
    ")\n",
    "plt.subplot(2, 2, 3)\n",
    "importances.sort_values().plot(kind='barh')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "\n",
    "# Plot 4: Confusion Matrix for best model\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['test_score'])[0]\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(y_test, best_predictions, normalize='true'),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    xticklabels=rf_classifier.classes_,\n",
    "    yticklabels=rf_classifier.classes_\n",
    ")\n",
    "plt.title(f'Confusion Matrix ({best_model_name})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the best model\n",
    "best_model = results[best_model_name]['pipeline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection & Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the best model (Random Forest)\n",
    "import pickle\n",
    "\n",
    "best_model = results['random_forest']['pipeline']\n",
    "\n",
    "# Save the model\n",
    "with open('jaguar_behavior_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# 2. Create a prediction function\n",
    "def predict_jaguar_behavior(jaguar_data):\n",
    "    \"\"\"\n",
    "    Predict jaguar behavior from movement data\n",
    "    \n",
    "    Parameters:\n",
    "    jaguar_data: DataFrame with required features:\n",
    "        - speed_mean, speed_max, speed_std\n",
    "        - distance_sum, distance_mean\n",
    "        - direction_mean, direction_std\n",
    "        - area_covered, movement_intensity\n",
    "        - path_efficiency, direction_variability\n",
    "        - hour, is_night, is_peak_activity\n",
    "    \n",
    "    Returns:\n",
    "    predicted_behavior: string indicating behavior class\n",
    "    \"\"\"\n",
    "    # Ensure all required features are present\n",
    "    required_features = [\n",
    "        'speed_mean', 'speed_max', 'speed_std',\n",
    "        'distance_sum', 'distance_mean',\n",
    "        'direction_mean', 'direction_std',\n",
    "        'area_covered', 'movement_intensity',\n",
    "        'path_efficiency', 'direction_variability',\n",
    "        'hour', 'is_night', 'is_peak_activity'\n",
    "    ]\n",
    "    \n",
    "    missing_features = [f for f in required_features if f not in jaguar_data.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing required features: {missing_features}\")\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = best_model.predict(jaguar_data[required_features])\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 3. Create example usage/demo\n",
    "def create_demo_prediction():\n",
    "    \"\"\"\n",
    "    Demonstrate model usage with example data\n",
    "    \"\"\"\n",
    "    # Create sample data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'speed_mean': [1.5],\n",
    "        'speed_max': [3.0],\n",
    "        'speed_std': [0.5],\n",
    "        'distance_sum': [2.0],\n",
    "        'distance_mean': [0.5],\n",
    "        'direction_mean': [180.0],\n",
    "        'direction_std': [45.0],\n",
    "        'area_covered': [1.0],\n",
    "        'movement_intensity': [3.0],\n",
    "        'path_efficiency': [0.8],\n",
    "        'direction_variability': [30.0],\n",
    "        'hour': [12],\n",
    "        'is_night': [0],\n",
    "        'is_peak_activity': [1]\n",
    "    })\n",
    "    \n",
    "    # Get prediction\n",
    "    behavior = predict_jaguar_behavior(sample_data)\n",
    "    \n",
    "    print(f\"Predicted behavior: {behavior[0]}\")\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    proba = best_model.predict_proba(sample_data)\n",
    "    behaviors = best_model.classes_\n",
    "    \n",
    "    print(\"\\nPrediction probabilities:\")\n",
    "    for behavior, prob in zip(behaviors, proba[0]):\n",
    "        print(f\"{behavior}: {prob:.2%}\")\n",
    "\n",
    "# 4. Add real-time prediction capability\n",
    "def process_new_movement_data(lat, lon, timestamp, previous_data=None):\n",
    "    \"\"\"\n",
    "    Process new movement data point and predict behavior\n",
    "    \n",
    "    Parameters:\n",
    "    lat: float - latitude\n",
    "    lon: float - longitude\n",
    "    timestamp: datetime - time of observation\n",
    "    previous_data: DataFrame - previous movement data for context\n",
    "    \n",
    "    Returns:\n",
    "    behavior: string - predicted behavior\n",
    "    \"\"\"\n",
    "    # Calculate required features from new data point\n",
    "    hour = timestamp.hour\n",
    "    is_night = 1 if (hour >= 18 or hour <= 6) else 0\n",
    "    is_peak_activity = 1 if hour in [5,6,7,17,18,19] else 0\n",
    "    \n",
    "    # If we have previous data, calculate movement features\n",
    "    if previous_data is not None:\n",
    "        # Calculate speed, distance, direction etc.\n",
    "        pass\n",
    "    else:\n",
    "        # Use default values when no history is available\n",
    "        pass\n",
    "    \n",
    "    # Create feature DataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        # Add features here based on calculations\n",
    "    })\n",
    "    \n",
    "    return predict_jaguar_behavior(new_data)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Demonstrating jaguar behavior prediction model:\")\n",
    "    create_demo_prediction()\n",
    "    \n",
    "    # Test loading saved model\n",
    "    print(\"\\nTesting model loading:\")\n",
    "    with open('jaguar_behavior_model.pkl', 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add behavioral prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
