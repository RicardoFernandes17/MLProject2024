{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jaguar Movement Pattern Analysis - Model Evaluation\n",
        "\n",
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcfeature\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Import custom modules\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_engineering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureEngineer\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbehavior_classifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JaguarBehaviorClassifier\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Import custom modules\n",
        "from src.data.data_loader import DataLoader\n",
        "from src.data.feature_engineering import FeatureEngineer\n",
        "from src.models.behavior_classifier import JaguarBehaviorClassifier\n",
        "from src.pipeline.training_pipeline import ModelTrainingPipeline\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model_path = Path('models/jaguar_behavior_model.pkl')\n",
        "with open(model_path, 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Load the test data\n",
        "data_loader = DataLoader(\n",
        "    'data/raw/jaguar_movement_data.csv',\n",
        "    'data/raw/jaguar_additional_information_2.csv'\n",
        ")\n",
        "data = data_loader.load_data()\n",
        "\n",
        "# Process data\n",
        "data = FeatureEngineer.add_time_features(data)\n",
        "data = FeatureEngineer.calculate_movement_features(data)\n",
        "window_data = FeatureEngineer.create_movement_windows(data)\n",
        "window_data = FeatureEngineer.classify_movement_state(window_data)\n",
        "\n",
        "# Clean data\n",
        "window_data = window_data.dropna()\n",
        "window_data = window_data[window_data['movement_state'] != 'unknown']\n",
        "\n",
        "# Define feature columns\n",
        "feature_cols = [\n",
        "    'speed_mean', 'speed_max', 'speed_std',\n",
        "    'distance_sum', 'distance_mean',\n",
        "    'direction_mean', 'direction_std',\n",
        "    'area_covered', 'movement_intensity',\n",
        "    'path_efficiency', 'direction_variability'\n",
        "]\n",
        "\n",
        "X = window_data[feature_cols]\n",
        "y = window_data['movement_state']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Performance Overview\n",
        "\n",
        "### 2.1 Basic Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get predictions\n",
        "y_pred = model.predict(X)\n",
        "y_prob = model.predict_proba(X)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y, y_pred))\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = (y == y_pred).mean()\n",
        "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', \n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title('Normalized Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "    \n",
        "    return cm\n",
        "\n",
        "classes = ['resting', 'foraging', 'traveling', 'exploring']\n",
        "cm = plot_confusion_matrix(y, y_pred, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detailed Analysis\n",
        "\n",
        "### 3.1 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_feature_importance(model, feature_names):\n",
        "    importances = model.classifier.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title(\"Feature Importances\")\n",
        "    plt.bar(range(len(importances)), importances[indices])\n",
        "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "plot_feature_importance(model, feature_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_roc_curves(y_true, y_prob, classes):\n",
        "    n_classes = len(classes)\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    # Calculate ROC curve and ROC area for each class\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true == classes[i], y_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    \n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curves(y, y_prob, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Behavioral Analysis\n",
        "\n",
        "### 4.1 Movement Patterns by Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_movement_patterns(data):\n",
        "    daily_patterns = pd.DataFrame({\n",
        "        'hour': data['hour'],\n",
        "        'state': data['movement_state']\n",
        "    })\n",
        "    \n",
        "    plt.figure(figsize=(15, 6))\n",
        "    movement_by_hour = pd.crosstab(daily_patterns['hour'], \n",
        "                                  daily_patterns['state'], \n",
        "                                  normalize='index')\n",
        "    movement_by_hour.plot(kind='area', stacked=True)\n",
        "    plt.title('Movement State Distribution Throughout the Day')\n",
        "    plt.xlabel('Hour of Day')\n",
        "    plt.ylabel('Proportion')\n",
        "    plt.legend(title='Movement State', bbox_to_anchor=(1.05, 1))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_movement_patterns(window_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Spatial Distribution of Behaviors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_spatial_behaviors(data):\n",
        "    fig, ax = plt.subplots(figsize=(15, 10),\n",
        "                          subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "    \n",
        "    # Add map features\n",
        "    ax.add_feature(cfeature.LAND)\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "    ax.add_feature(cfeature.COASTLINE)\n",
        "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "    \n",
        "    # Plot points colored by movement state\n",
        "    states = data['movement_state'].unique()\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(states)))\n",
        "    \n",
        "    for state, color in zip(states, colors):\n",
        "        mask = data['movement_state'] == state\n",
        "        ax.scatter(data.loc[mask, 'longitude'],\n",
        "                  data.loc[mask, 'latitude'],\n",
        "                  c=[color],\n",
        "                  label=state,\n",
        "                  alpha=0.6,\n",
        "                  s=50)\n",
        "    \n",
        "    plt.legend(title='Movement State')\n",
        "    plt.title('Spatial Distribution of Movement Behaviors')\n",
        "    plt.show()\n",
        "\n",
        "plot_spatial_behaviors(window_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Validation\n",
        "\n",
        "### 5.1 Prediction Confidence Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_prediction_confidence(y_prob, y_pred, threshold=0.8):\n",
        "    # Get maximum probability for each prediction\n",
        "    max_probs = np.max(y_prob, axis=1)\n",
        "    \n",
        "    # Analyze high confidence predictions\n",
        "    high_conf_mask = max_probs >= threshold\n",
        "    high_conf_accuracy = (y_pred[high_conf_mask] == y[high_conf_mask]).mean()\n",
        "    \n",
        "    print(f\"Predictions with confidence >= {threshold}:\")\n",
        "    print(f\"Count: {high_conf_mask.sum()} ({high_conf_mask.mean()*100:.1f}% of total)\")\n",
        "    print(f\"Accuracy: {high_conf_accuracy:.4f}\")\n",
        "    \n",
        "    # Plot confidence distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(max_probs, bins=50)\n",
        "    plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold})')\n",
        "    plt.title('Distribution of Prediction Confidence')\n",
        "    plt.xlabel('Maximum Probability')\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "analyze_prediction_confidence(y_prob, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.11' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/ricardofernandes/.pyenv/versions/3.11.11/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def analyze_errors(y_true, y_pred, data):\n",
        "    # Find misclassified instances\n",
        "    errors = y_true != y_pred\n",
        "    error_data = data[errors].copy()\n",
        "    \n",
        "    # Analyze errors by time of day\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.countplot(data=error_data, x='time_of_day')\n",
        "    plt.title('Errors by Time of Day')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "    # Analyze errors by speed range\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.boxplot(data=error_data, x='movement_state', y='speed_mean')\n",
        "    plt.title('Error Distribution by Speed')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\nError Analysis Summary:\")\n",
        "    print(\"-----------------------\")\n",
        "    print(f\"Total errors: {errors.sum()} ({errors.mean()*100:.1f}% of data)\")\n",
        "    print(\"\\nErrors by true state:\")\n",
        "    print(error_data['movement_state'].value_counts(normalize=True))\n",
        "\n",
        "analyze_errors(y, y_pred, window_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Individual Jaguar Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_individual_performance(data, y_true, y_pred):\n",
        "    results = []\n",
        "    \n",
        "    for jaguar_id in data['individual_id'].unique():\n",
        "        mask = data['individual_id'] == jaguar_id\n",
        "        \n",
        "        # Calculate metrics for this jaguar\n",
        "        accuracy = (y_true[mask] == y_pred[mask]).mean()\n",
        "        behavior_dist = data.loc[mask, 'movement_state'].value_counts(normalize=True)\n",
        "        \n",
        "        results.append({\n",
        "            'jaguar_id': jaguar_id,\n",
        "            'accuracy': accuracy,\n",
        "            'n_samples': mask.sum(),\n",
        "            'behavior_distribution': behavior_dist\n",
        "        })\n",
        "    \n",
        "    # Plot individual accuracies\n",
        "    results_df = pd.DataFrame(results)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(data=results_df, x='jaguar_id', y='accuracy')\n",
        "    plt.title('Model Accuracy by Individual')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "    return results_df\n",
        "\n",
        "individual_results = analyze_individual_performance(window_data, y, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusions and Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_conclusions():\n",
        "    print(\"Model Performance Summary:\")\n",
        "    print(\"-------------------------\")\n",
        "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nStrengths:\")\n",
        "    print(\"- Most reliable in distinguishing resting vs. traveling states\")\n",
        "    print(\"- High confidence predictions (>0.8) show improved accuracy\")\n",
        "    print(\"- Consistent performance across different times of day\")\n",
        "    \n",
        "    print(\"\\nLimitations:\")\n",
        "    print(\"- Some confusion between foraging and exploring states\")\n",
        "    print(\"- Performance varies across individuals\")\n",
        "    print(\"- Edge cases in transition periods\")\n",
        "    \n",
        "    print(\"\\nRecommendations:\")\n",
        "    print(\"1. Consider collecting more data for underrepresented behaviors\")\n",
        "    print(\"2. Investigate individual-specific movement patterns\")\n",
        "    print(\"3. Refine feature engineering for transition periods\")\n",
        "    print(\"4. Implement confidence thresholds for critical applications\")\n",
        "\n",
        "print_conclusions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook provides a comprehensive evaluation of the jaguar movement behavior model, including:\n",
        "1. Basic performance metrics\n",
        "2. Detailed behavior analysis\n",
        "3. Spatial and temporal patterns\n",
        "4. Individual jaguar analysis\n",
        "5. Error analysis\n",
        "6. Recommendations for improvement\n",
        "\n",
        "The visualizations and analyses help understand both the model's strengths and limitations, providing insights for future improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
